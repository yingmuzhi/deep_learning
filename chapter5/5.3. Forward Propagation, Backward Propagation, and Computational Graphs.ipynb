{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## x.1 反向传播和L2正则化\n",
    "\n",
    "在前面的一些章节中，我们的着眼点都在forward函数，即进行forward propagation前向传播书写，而在计算梯度时我们使用的都是深度学习框架下提供的反向传播函数。\n",
    "\n",
    "这一章节中我们将对automatic differentiation自动微分，backward propagation反向传播，computational graph计算图进行一定了解。\n",
    "\n",
    "我们这一章节的模型以带有weight decay权重衰减（L2正则化）的单隐藏层的MLP为主。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**反向传播是指计算神经网络参数梯度的方法。简而言之，该方法根据微积分的链式法则，从输出层到输入层以相反的顺序遍历网络**。\n",
    "\n",
    "**而L2正则化，weight decay即将weight增加到loss中**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
